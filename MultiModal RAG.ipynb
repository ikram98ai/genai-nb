{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380623e7-167c-4dce-8836-227590e0ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bd959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/ad/ec/8ae848b4aad905e1a80d0e99b5e6ecc9c0ac0086e1e4299e44e61f2d8ca3/unstructured-0.14.3-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.14.3-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: chardet in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (4.0.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Obtaining dependency information for filetype from https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Obtaining dependency information for python-magic from https://files.pythonhosted.org/packages/6c/73/9f872cb81fc5c3bb48f7227872c28975f998f3e7c2b1c16e95e6432bbb90/python_magic-0.4.27-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (0.8.10)\n",
      "Requirement already satisfied: requests in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/e6/90/20ad30babfa8f2b5ab46281d8e17bdfdbb3ac294cda14d525b9c2d958846/emoji-2.12.1-py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dataclasses-json (from unstructured)\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/92/70/382283d80cb998ebc0089428b109bbe606ec9dce891a3cb1468c03ed0ad6/dataclasses_json-0.6.6-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Obtaining dependency information for python-iso639 from https://files.pythonhosted.org/packages/01/08/5e649cf18dec750d498c53c6c8eb1d9790752ebd50fa7f7e69cc0c277cfe/python_iso639-2024.4.27-py3-none-any.whl.metadata\n",
      "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m375.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (1.24.3)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/e5/b0/c4ef113f88d3c667f5672e37ba152b4ae1b91c7b90455b7a0ff51eba6d31/rapidfuzz-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading rapidfuzz-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Obtaining dependency information for backoff from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (4.7.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Obtaining dependency information for unstructured-client from https://files.pythonhosted.org/packages/b0/bc/c74937363c2657a77e4c4e105b7a004203ad53f128b5caf5dbb9dc9458d1/unstructured_client-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading unstructured_client-0.22.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: wrapt in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ik/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/be/24/cbb242420021a79c87768dcd22ce028f48ef40913239ad6106c8a557f52c/marshmallow-3.21.2-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six in /home/ik/anaconda3/lib/python3.11/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ik/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/ik/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ik/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /home/ik/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ik/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ik/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ik/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ik/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (2023.7.22)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->unstructured)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/40/26/f35951c45070edc957ba40a5b1db3cf60a9dbb1b350c2d5bef03e01e61de/charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for deepdiff>=6.0 from https://files.pythonhosted.org/packages/18/e6/d27d37dc55dbf40cdbd665aa52844b065ac760c9a02a02265f97ea7a4256/deepdiff-7.0.1-py3-none-any.whl.metadata\n",
      "  Downloading deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for jsonpath-python>=1.0.6 from https://files.pythonhosted.org/packages/16/8a/d63959f4eff03893a00e6e63592e3a9f15b9266ed8e0275ab77f8c7dbc94/jsonpath_python-1.0.6-py3-none-any.whl.metadata\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured-client->unstructured) (23.1)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for pypdf>=4.0 from https://files.pythonhosted.org/packages/c9/d1/450b19bbdbb2c802f554312c62ce2a2c0d8744fe14735bc70ad2803578c7/pypdf-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ik/anaconda3/lib/python3.11/site-packages (from unstructured-client->unstructured) (2.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib3<3,>=1.21.1 (from requests->unstructured)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
      "  Obtaining dependency information for ordered-set<4.2.0,>=4.1.0 from https://files.pythonhosted.org/packages/33/55/af02708f230eb77084a299d7b08175cff006dea4f2721074b92cdb0296c0/ordered_set-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading unstructured-0.14.3-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m346.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m432.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading rapidfuzz-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m670.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m148.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m796.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m742.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ad1111bdf30d56e091fbe596be35057f3bb5ee06c73d05192d5adb8af0aedd64\n",
      "  Stored in directory: /home/ik/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, urllib3, typing-inspect, rapidfuzz, python-magic, python-iso639, pypdf, ordered-set, marshmallow, langdetect, jsonpath-python, emoji, charset-normalizer, backoff, deepdiff, dataclasses-json, unstructured-client, unstructured\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "botocore 1.29.76 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires PyYAML==6.0.1, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed backoff-2.2.1 charset-normalizer-3.3.2 dataclasses-json-0.6.6 deepdiff-7.0.1 emoji-2.12.1 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 marshmallow-3.21.2 ordered-set-4.1.0 pypdf-4.2.0 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.2 typing-inspect-0.9.0 unstructured-0.14.3 unstructured-client-0.22.0 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0040b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97fc0c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unstructured'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[1;32m      3\u001b[0m pdf_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m raw_elements \u001b[38;5;241m=\u001b[39m partition_pdf(\n\u001b[1;32m      6\u001b[0m     filename\u001b[38;5;241m=\u001b[39m pdf_file_name,\n\u001b[1;32m      7\u001b[0m     chunking_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby_title\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi_res\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unstructured'"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "pdf_file_name = ''\n",
    "\n",
    "raw_elements = partition_pdf(\n",
    "    filename= pdf_file_name,\n",
    "    chunking_strategy='by_title',\n",
    "    infer_table_structure= True,\n",
    "    max_characters= 1000,\n",
    "    new_after_n_chars=1500,\n",
    "    combine_text_under_n_chars=250,\n",
    "    strategy='hi_res'\n",
    ")\n",
    "\n",
    "pdf_file_path=''\n",
    "extract_images_from_pdf(pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1d5cc",
   "metadata": {},
   "source": [
    "## Organize text from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f27ea-6e18-46c9-9a9e-8b21284c7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "texts = []\n",
    "\n",
    "for element in raw_elements:\n",
    "    if 'unstructured.documents.elements.Table' in str(type(element)):\n",
    "        tables.appends(str(element))\n",
    "    elif 'unstructured.documents.elements.CompositeElement' in str(type(element)):\n",
    "        texts.appends(str(element))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05e8c2",
   "metadata": {},
   "source": [
    "## Use the Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69d7f9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9cd119",
   "metadata": {},
   "source": [
    "## Generate Texts and Tables summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cbe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME =  'models/gemini-1.5-pro-latest'\n",
    "model = genai.GenertiveModel(model_name=MODEL_NAME)\n",
    "\n",
    "\n",
    "def make_prompt(element):\n",
    "    return f\"\"\" You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element}\"\"\"\n",
    "\n",
    "\n",
    "def generate_text_summaries (texts, tables, summarize_texts = False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    Args:\n",
    "\n",
    "    texts:List of str\n",
    "    tables:List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    text_summaries, table_summaries = [], []\n",
    "    if texts:\n",
    "        if summarize_texts:\n",
    "            for text in texts:\n",
    "                prompt = make_prompt(text)\n",
    "                response = model.generate_content(prompt)\n",
    "                text_summaries.append(response.text)\n",
    "        else:\n",
    "            text_summaries = text\n",
    "        \n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                prompt = make_prompt(table)\n",
    "                response = model.generate_content(prompt)\n",
    "                table_summaries.append(response.text)\n",
    "        else:\n",
    "        text_summaries = text\n",
    "    return text_summaries, table_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_summaries, table_summaries = generate_text_summaries(texts,tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97e038",
   "metadata": {},
   "source": [
    "## Generate Images summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"Encodes an image to a base64 string.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64,b64encode (image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def generate_image_summaries(image_directory):\n",
    "    \"\"\"Generates summaries for images in the specified directory.\"\"\"\n",
    "    img_base64_list = [] # Store base64 encoded images\n",
    "    image_summaries = [] # Store image summaries\n",
    "    model genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "    prompt = \"\"\"You are an automotive assistant tasked with summarizing images for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw image. \\\n",
    "    Describe concisely the characteristics (shape, color), but do not infer what the image means. \\\n",
    "    Only describe the characteristics of the image you see.\"\"\"\n",
    "    \n",
    "    for filename in sorted(os.listdir(image_directory)):\n",
    "        if filename.endswith(\".png\"):\n",
    "        image path = os.path.join(image directory, filename)\n",
    "        base64 image encode_image(image_path)\n",
    "        img_base64_list.append(base64_image)\n",
    "        with PIL.Image.open(image_path) as img:\n",
    "            response model.generate_content([prompt, img])\n",
    "            image summaries.append(response.text)\n",
    "        \n",
    "    return image_summaries, img_base64_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc205cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = ''\n",
    "image_summaries, img_base64_list = generate_image_summaries(image_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5f1f4",
   "metadata": {},
   "source": [
    "## Setup Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62356b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "display_name=\"rag_langchain_streaming_index\",\n",
    "dimensions=768,\n",
    "approximate_neighbors_count=150,\n",
    "leaf_node_embedding_count=500,\n",
    "leaf_nodes_to_search_percent=7,\n",
    "description=\"Multimodal RAG LangChain Stream Index,\n",
    "index_update_method=\"stream_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d512912",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint = index_endpoint.deploy_index(\n",
    "index=index, deployed_index_id=\"rag_langchain_deployed_streaming_index\" )\n",
    "index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ddac4",
   "metadata": {},
   "source": [
    "## Define a vector store with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fe820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vectorstore to use to index the summaries\n",
    "vectorstore = VectorSearchVectorStore.from_components(\n",
    "project_id=PROJECT_ID,\n",
    "region=LOCATION,\n",
    "gcs_bucket_name=GCS_BUCKET,\n",
    "index_id=index_id,\n",
    "endpoint_id=endpoint_id,\n",
    "embedding-GoogleGenerativeAIEmbeddings (model=\"models/embedding-001\"),\n",
    "stream_update=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the document store\n",
    "docstore InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "#Create the multi-vector retriever\n",
    "retriever_multi_vector_img = MultiVectorRetriever (\n",
    "vectorstore=vectorstore,\n",
    "docstore=docstore,\n",
    "id_key=id_key,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7196a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine raw document contents\n",
    "doc_contents= texts + tables + img_base64_list\n",
    "doc_ids = [str(uuid.uuid4()) for in doc_contents] -\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(texts + table_summaries + image_summaries)\n",
    "]\n",
    "retriever_multi_vector_img.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "#Generate embeddings for all chunks and stream them to the vector stom\n",
    "retriever_multi_vector_img.vectorstore.add_documents(summary_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e535d5",
   "metadata": {},
   "source": [
    "## Stage 2 Q&A Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57644a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "#Create RAG chain\n",
    "\n",
    "chain_multimodal_rag = (\n",
    "    {\n",
    "    \"context\": retriever_multi_vector_img | RunnableLambda(split_image_text_types),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda (img_prompt_func)\n",
    "    | ChatGoogleGenerativeAI (\n",
    "        temperature=0, model=\"gemini-1.5-pro-latest\", max_output_tokens=1024\n",
    "    #Multi-modal LLM\n",
    "    )\n",
    "    | StroutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db07792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multimodal search function\n",
    "def multimodal_search(query: str) -> str:\n",
    "    \"\"\"Performs a multimodal search for a given query, retrieving relevant documents and invoking a chain for generating\n",
    "        Args:\n",
    "            query: The search query string.\n",
    "        Returns:\n",
    "            The final result generated by the chain.\n",
    "    \"\"\"\n",
    "    #retriever_multi_vector_img: The retriever object for fetching relevant documents (images and text). \n",
    "    docs=retriever_multi_vector_img.invoke(query, limit=10)\n",
    "    #split image_text_types: A function to split fetched documents into separate image and tex \n",
    "    source_docs = split_image_text_types(docs)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(\"Retrieved Text Sources:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, source in enumerate (source_docs[\"texts\"]):\n",
    "        source_without_linebreaks = source.replace(\"\\n\", \"\") # Remove line breaks\n",
    "        print(f\"Retrieved chunk {1+1}: {source_without_linebreaks}\")\n",
    "    for img data in source_docs[\"images\"]:\n",
    "        try:\n",
    "            print(\"\\n\")\n",
    "            print('_'*80)\n",
    "            print(\"\\nRetrieved Images Matching Source Documents:\")\n",
    "            print(\"=\"*80)\n",
    "            display (Image (base64.b64decode(img_data)))\n",
    "        except (TypeError, binascii.Error):\n",
    "            print(\"Error decoding or displaying an image. Skipping...\")\n",
    "    #chain_multimodal_rag: The chain object for processing and generating a result.\n",
    "    result=chain_multimodal_rag.invoke(query)\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"RAG Pipeline Summarized Answer:\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcd03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
